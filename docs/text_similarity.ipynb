{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Get sample data\n",
    "Where to start? I have just copied from Wikipedia 4 articles: 2 football players and 2 cars. I think it will be good for matching and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First \"car\" text has 7924 characters\n",
      "Sample >> The Citroën C4 is a compact car (C-segment in Europe) produced by French automaker Citroën since aut\n",
      "Second \"car\" text has 6165 characters\n",
      "Sample >> The Audi 80 is a compact executive car produced by the German manufacturer Audi (initially known as \n",
      "First \"player\" text has 3876 characters\n",
      "Sample >> Marek Citko (born March 27, 1974 Białystok) is a retired Polish football player, who most frequently\n",
      "Second \"player\" text has 7751 characters\n",
      "Sample >> Éric Daniel Pierre Cantona (French pronunciation: ​[e'ʁik kɑ̃to'na]; born 24 May 1966) is a French a\n"
     ]
    }
   ],
   "source": [
    "car_text_1 = open('testdata/citroen_c4.txt','r', encoding='utf-8').read()\n",
    "print('First \"car\" text has %d characters' % len(car_text_1))\n",
    "print('Sample >> %s' % car_text_1[:100])\n",
    "car_text_2 = open('testdata/audi_80.txt','r', encoding='utf-8').read()\n",
    "print('Second \"car\" text has %d characters' % len(car_text_2))\n",
    "print('Sample >> %s' % car_text_2[:100])\n",
    "\n",
    "player_text_1 = open('testdata/citko.txt','r', encoding='utf-8').read()\n",
    "print('First \"player\" text has %d characters' % len(player_text_1))\n",
    "print('Sample >> %s' % player_text_1[:100])\n",
    "player_text_2 = open('testdata/cantona.txt','r', encoding='utf-8').read()\n",
    "print('Second \"player\" text has %d characters' % len(player_text_2))\n",
    "print('Sample >> %s' % player_text_2[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Having that fields time for play!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stopwords\n",
    "Remove stop words, there are not a feature of text! Moreover with de-capitalize all words to make them equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Marek Citko (born March 27, 1974 Białystok) is a retired Polish football player, who most frequently\n",
      "After:\n",
      "marek citko (born march 27, 1974 białystok) retired polish football player, frequently performed off\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def text_without_stopwords(input):\n",
    "    without = [z for z in input.lower().split() if z not in stop]\n",
    "    return ' '.join(without)\n",
    "\n",
    "print(\"Before cleaning:\")\n",
    "print(player_text_1[:100])\n",
    "print(\"After:\")\n",
    "player_text_1 = text_without_stopwords(player_text_1)\n",
    "print(player_text_1[:100])\n",
    "\n",
    "player_text_2 = text_without_stopwords(player_text_2)\n",
    "car_text_1 = text_without_stopwords(car_text_1)\n",
    "car_text_2 = text_without_stopwords(car_text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Time for normalizing\n",
    "Now we may want to remove all endings and remove punctuation. This will make text one long text, easier to vectorize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "print(stemmer.stem(\"retired\"))\n",
    "print(stemmer.stem(\"frequently\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So this is how stemming works. Now let's apply it to whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marek', 'citko', 'born', 'march', '27', '1974', 'białystok', 'retir', 'polish', 'footbal', 'player', 'frequent', 'perform', 'offens', 'midfield', 'first', 'club', 'włókniarz', 'białystok', 'hist']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.translate(remove_punctuation_map)))\n",
    "print(normalize(player_text_1)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cosine similarity\n",
    "`normalize` function will be used now, we will now convert our texts into vectors and compare them using cosine similarity. Then there is going to be short test are we able to MachineLearning way to deduct which are \"cars\" vs \"players\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player Citko vs Player Cantona = 0.140 \n",
      "Car Citronen vs Player Citko = 0.024 \n",
      "Car Audi vs Player Citko = 0.019\n",
      "Cars are similar! 0.119 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize)\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n",
    "print('Player Citko vs Player Cantona = %.3f ' % cosine_sim(player_text_2, player_text_1))\n",
    "print('Car Citronen vs Player Citko = %.3f ' % cosine_sim(car_text_1, player_text_1))\n",
    "print('Car Audi vs Player Citko = %.3f' % cosine_sim(car_text_2, player_text_1))\n",
    "print('Cars are similar! %.3f ' % cosine_sim(car_text_1, car_text_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summary\n",
    "Voila. Cars had greater similarity between each other in \"same\" group. The same with football players. So we can tell how we measure text similarity in simple way!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}